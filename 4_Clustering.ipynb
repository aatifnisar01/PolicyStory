{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B046hV9AcQb9"
   },
   "source": [
    "# Necessary Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116058,
     "status": "ok",
     "timestamp": 1743950776538,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "ZGyWaBBrda-B",
    "outputId": "8cbdf01c-6ef0-4e30-b6f5-8da0616d8422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1743950776541,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "uhelOwSUaNUO",
    "outputId": "845d24f7-5292-44c4-e3d2-1b194f4aafe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/MediaCloud\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/MediaCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1743950776542,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "V4A5YTpVaVsM",
    "outputId": "8828150e-94b1-4944-b74a-f40cb764ab5d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/MediaCloud'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "pwd = os.getcwd()\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jom3vuAbh-4t"
   },
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81407,
     "status": "ok",
     "timestamp": 1743830895859,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "6oowBbFvSVl8",
    "outputId": "c0e84947-bbe1-4046-bafe-a5eb66109f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.23 (from langchain_community)\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.22)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.4.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.49\n",
      "    Uninstalling langchain-core-0.3.49:\n",
      "      Successfully uninstalled langchain-core-0.3.49\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.3.7\n",
      "    Uninstalling langchain-text-splitters-0.3.7:\n",
      "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.22\n",
      "    Uninstalling langchain-0.3.22:\n",
      "      Successfully uninstalled langchain-0.3.22\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.23 langchain-core-0.3.51 langchain-text-splitters-0.3.8 langchain_community-0.3.21 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
    "!pip install sentencepiece\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ciF0CzxmSFD3"
   },
   "source": [
    "# Hugging Face and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1743830895859,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "7bxT_218JqZi",
    "outputId": "f5e1a24d-4d10-47ad-a6e1-e4cfc25c2337"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/MediaCloud'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOdA1H2LctpK"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your Hugging Face access token (get it from https://huggingface.co/settings/tokens)\n",
    "login('ENTER TOKEN HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rvvG-gActmk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from  langchain import LLMChain, HuggingFacePipeline, PromptTemplate\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt343jU-c7IU"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "1b892e020fc44c64ac572362006ae18c",
      "d0a24009a7c24f57ae4ad703bde8afe7",
      "38c7fb463ae747e78337dac59213d672",
      "7c6adf57cf64466b8b487ee344d07167"
     ]
    },
    "executionInfo": {
     "elapsed": 3065,
     "status": "ok",
     "timestamp": 1743830912126,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "IstWzgH6ctj2",
    "outputId": "8fedabba-bb75-44f3-a312-2301b925a972"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b892e020fc44c64ac572362006ae18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a24009a7c24f57ae4ad703bde8afe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c7fb463ae747e78337dac59213d672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6adf57cf64466b8b487ee344d07167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "#model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "d6a1c9c769ca4342ae8536f9be446fe0",
      "9335ab219fb9416c9d20ca4a9e0b44a9",
      "2ff6f8e7a3e24067922ba9fbc152abc6",
      "a57b1bdc82c847e0a116740034b403aa",
      "0cbc538e3d084334aa79b2f6374be1e0",
      "3b449e8b475d40ef91e1358ec4cf6d7a",
      "6504a5b2a07a4334be4bed8f4de14461"
     ]
    },
    "executionInfo": {
     "elapsed": 55828,
     "status": "ok",
     "timestamp": 1743830967952,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "7_EYhLphcthU",
    "outputId": "751fee84-76e4-453c-a148-aa55fb0d484e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a1c9c769ca4342ae8536f9be446fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9335ab219fb9416c9d20ca4a9e0b44a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff6f8e7a3e24067922ba9fbc152abc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57b1bdc82c847e0a116740034b403aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbc538e3d084334aa79b2f6374be1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b449e8b475d40ef91e1358ec4cf6d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6504a5b2a07a4334be4bed8f4de14461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    #max_length=4096,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "#    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743830967952,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "AKtyVwTucte-",
    "outputId": "6675680f-3ffc-419c-f70d-2a8fdea871dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-9410ce7de563>:1: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjdXqyunRN_U"
   },
   "source": [
    "# Output all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwYfPQydRQCY"
   },
   "outputs": [],
   "source": [
    "def assign_cluster(title, llm):\n",
    "    template = f\"\"\"\n",
    "            Given the title and first paragraph of an article (delimited by triple\n",
    "            backticks), create an appropriate cluster that best fits the overall\n",
    "            theme of the article.\n",
    "            - First, generate a concise and meaningful cluster name based on\n",
    "              the title and text.\n",
    "            - Then assign the article to that single cluster.\n",
    "            Please ensure that the title is classified into only one of the clusters.\n",
    "            “‘title“‘\n",
    "            “‘first paragraph“‘\n",
    "            CLUSTER:\n",
    "        \"\"\"\n",
    "    prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
    "    llm_chain = LLMChain(prompt=prompt_template, llm=llm)\n",
    "\n",
    "    cluster = llm_chain.run({\"title\": title}).strip()\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLOMHfYPRP_8"
   },
   "outputs": [],
   "source": [
    "# Input and output folder paths\n",
    "input_folder = 'Farmers_Protest/4.UPDATED_Parsed_YearWise_Data_with_Summaries'\n",
    "output_folder = 'Farmers_Protest/5.Clustered_Articles'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "XD74DojjRP9j",
    "outputId": "11810a5f-a092-4541-da93-0d0faceffecc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a84f367b46eb>:16: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(prompt=prompt_template, llm=llm)\n",
      "<ipython-input-11-a84f367b46eb>:18: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  cluster = llm_chain.run({\"title\": title}).strip()\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: Farmers_Protest/5.Clustered_Articles/Clustered_Parsed_data_2024_with_summaries.csv\n",
      "Processed and saved: Farmers_Protest/5.Clustered_Articles/Clustered_Parsed_data_2022_with_summaries.csv\n",
      "Processed and saved: Farmers_Protest/5.Clustered_Articles/Clustered_Parsed_data_2021_with_summaries.csv\n",
      "Processed and saved: Farmers_Protest/5.Clustered_Articles/Clustered_Parsed_data_2020_with_summaries.csv\n",
      "All files processed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Loop through all CSV files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".csv\"):  # Only process CSV files\n",
    "        input_file = os.path.join(input_folder, file_name)\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(input_file)\n",
    "\n",
    "        # Ensure required columns exist\n",
    "        if not {'title', 'parsed_text', 'parsed_summary'}.issubset(df.columns):\n",
    "            print(f\"Skipping {file_name} as it doesn't contain required columns.\")\n",
    "            continue\n",
    "\n",
    "        # Keep only the desired columns\n",
    "        df = df[['title', 'parsed_text', 'parsed_summary']]\n",
    "\n",
    "        # Apply clustering to each article title\n",
    "        df['cluster'] = df['title'].apply(lambda title: assign_cluster(title, llm))\n",
    "\n",
    "        # Save the processed DataFrame to the output folder\n",
    "        output_file = os.path.join(output_folder, f\"Clustered_{file_name}\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"Processed and saved: {output_file}\")\n",
    "\n",
    "print(\"All files processed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRDclouTtDJT"
   },
   "source": [
    "# Extract Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1743950776543,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "57jczNNRtGiI",
    "outputId": "4c1519ba-f890-4d77-e2fb-2ab0d73c8732"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/MediaCloud'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "eMpukmjgu-Oa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LUUcywQKtIwa"
   },
   "outputs": [],
   "source": [
    "input_folder = 'Farmers_Protest/5.Clustered_Articles'\n",
    "output_folder = 'Farmers_Protest/6.UPDATED_Clustered_Articles'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mSOmBNwstU61",
    "outputId": "bf220c4d-b336-486a-b0dc-c8c41701a088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: Farmers_Protest/6.UPDATED_Clustered_Articles/Clustered_Parsed_data_2024_with_summaries.csv\n",
      "Processed and saved: Farmers_Protest/6.UPDATED_Clustered_Articles/Clustered_Parsed_data_2022_with_summaries.csv\n",
      "Processed and saved: Farmers_Protest/6.UPDATED_Clustered_Articles/Clustered_Parsed_data_2021_with_summaries.csv\n",
      "Processed and saved: Farmers_Protest/6.UPDATED_Clustered_Articles/Clustered_Parsed_data_2020_with_summaries.csv\n"
     ]
    }
   ],
   "source": [
    "# Define a function to replace the entire text with the extracted cluster\n",
    "def replace_with_cluster(article_text):\n",
    "    \"\"\"\n",
    "    Replace the entire text with the cluster value extracted after the first 'CLUSTER:' keyword.\n",
    "    \"\"\"\n",
    "    # Regex to match the word 'CLUSTER:' and capture the text after it\n",
    "    pattern = r\"CLUSTER:\\s*(.*?)(?:\\n|$)\"\n",
    "    match = re.search(pattern, article_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()  # Extract the cluster name\n",
    "    return article_text  # If no match is found, keep the original text\n",
    "\n",
    "# Process each CSV file in the input folder\n",
    "csv_files = glob(os.path.join(input_folder, '*.csv'))  # Get all CSV files in the folder\n",
    "\n",
    "for file_path in csv_files:\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Apply the function to the 'cluster' column to replace its content\n",
    "    if 'cluster' in df.columns:  # Ensure the 'cluster' column exists\n",
    "        df['cluster'] = df['cluster'].apply(replace_with_cluster)\n",
    "\n",
    "        # Save the updated dataframe to a new CSV file in the output folder\n",
    "        file_name = os.path.basename(file_path)  # Get the file name\n",
    "        output_csv_path = os.path.join(output_folder, file_name)\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "        print(f\"Processed and saved: {output_csv_path}\")\n",
    "    else:\n",
    "        print(f\"Skipping {file_path}: 'cluster' column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GR2bBBPHy-re"
   },
   "source": [
    "# Separate based on similar clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "affMKLIA0p3A"
   },
   "source": [
    "### SPECIFY YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FxyelkFu4rx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxEKRofszDmU"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Farmers_Protest/6.UPDATED_Clustered_Articles/Clustered_Parsed_data_2024_with_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eb9qtUZz0GPt"
   },
   "outputs": [],
   "source": [
    "output_folder = 'Farmers_Protest/7.Separate_Clusters/2024'  # Specify the folder to save the files\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ur_MCscUzMRX"
   },
   "outputs": [],
   "source": [
    "unique_clusters = df['cluster'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743951020002,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "Os6Aj8IHzNFt",
    "outputId": "1c3fe7e7-74e6-4c7d-f32e-bfd232643145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files saved in Farmers_Protest/7.Separate_Clusters/2024\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each cluster and save the corresponding rows to a CSV\n",
    "for cluster in unique_clusters:\n",
    "    # Filter the DataFrame for the current cluster\n",
    "    cluster_data = df[df['cluster'] == cluster]\n",
    "\n",
    "    # Replace problematic characters in the file name (e.g., slashes, spaces)\n",
    "    safe_cluster_name = cluster.replace(' ', '_').replace('/', '_')\n",
    "\n",
    "    # Create a file name using the cluster name\n",
    "    output_file = os.path.join(output_folder, f\"{safe_cluster_name}.csv\")\n",
    "\n",
    "    # Save the filtered data to a CSV file\n",
    "    cluster_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"CSV files saved in {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2HtSDN4zOht"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "B046hV9AcQb9",
    "Jom3vuAbh-4t",
    "ciF0CzxmSFD3",
    "HRDclouTtDJT",
    "affMKLIA0p3A"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
